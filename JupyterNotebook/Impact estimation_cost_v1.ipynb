{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import glob\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import math\n",
    "import os\n",
    "import plotly.io as pio\n",
    "# The bin folder has the DLLs\n",
    "os.environ['path'] += r';C:/Users/JKIM4/Downloads/vips-dev-w64-all-8.11.0/vips-dev-8.11/bin'\n",
    "import pyvips\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "dir_code = \"../run\"\n",
    "dir_data = \"../run/data\"\n",
    "dir_results = \"../run/results\"\n",
    "\n",
    "# setting configs json file path\n",
    "file_configs = dir_code + \"/configs.json\"\n",
    "\n",
    "\n",
    "# reading configs json file\n",
    "print(\"reading configuration json file from = {}\".format(file_configs))\n",
    "with open(file_configs, \"r\") as read_file:\n",
    "    configs = json.load(read_file)\n",
    "    \n",
    "configs['dir_results'] = dir_results\n",
    "configs['dir_data'] = dir_data\n",
    "    \n",
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "################################################################################################\n",
    "\n",
    "def gas_rate(site_id, startyear, endyear):\n",
    "\n",
    "    headers = {'Content-type': 'application/json'}\n",
    "    data = json.dumps({\"seriesid\": [site_id],\"startyear\":startyear, \"endyear\":endyear})\n",
    "\n",
    "    p = requests.post('https://api.bls.gov/publicAPI/v1/timeseries/data/', data=data, headers=headers)\n",
    "    json_data = json.loads(p.text)\n",
    "    df_gas = pd.DataFrame()\n",
    "    \n",
    "    print(json_data)\n",
    "    \n",
    "    for series in json_data['Results']['series']:\n",
    "\n",
    "        i = 0\n",
    "        for item in series['data']:\n",
    "            year = item['year']\n",
    "            period = item['period']\n",
    "            value = item['value']\n",
    "            footnotes=\"\"\n",
    "            for footnote in item['footnotes']:\n",
    "                if footnote:\n",
    "                    footnotes = footnotes + footnote['text'] + ','\n",
    "\n",
    "            if 'M01' <= period <= 'M12':\n",
    "                df_gas.at[i,'year'] = year\n",
    "                df_gas.at[i,'period'] = period\n",
    "                df_gas.at[i,'value'] = value\n",
    "            i = i+1\n",
    "\n",
    "    years = df_gas['year'].unique()          \n",
    "\n",
    "    for year in years:\n",
    "        df_gas_filtered = df_gas.loc[df_gas['year']==year]\n",
    "        if len(df_gas_filtered) == 12:\n",
    "            break\n",
    "    return df_gas_filtered\n",
    "\n",
    "################################################################################################\n",
    "#----------------------------------------------------------------------------------------------#\n",
    "################################################################################################\n",
    "\n",
    "def utilRates(df,utility,sector,name):  # Electric\n",
    "\n",
    "    df_filtered = df.loc[df['utility'] ==utility]\n",
    "    df_filtered = df_filtered.loc[df_filtered['sector'] ==sector]\n",
    "    df_filtered = df_filtered.loc[df_filtered['name'] == name]\n",
    "    df_filtered['startdate'] = pd.to_datetime(df_filtered['startdate'], format='%m/%d/%Y %H:%M')\n",
    "    df_filtered.sort_values(by='startdate')\n",
    "    df_final = df_filtered.iloc[-1:].reset_index()\n",
    "    cols = df_final.columns\n",
    "\n",
    "    # filtering energy rates\n",
    "    energyrates = [col for col in cols if 'energyratestructure' in col ]\n",
    "    df_energyrates = df_final[energyrates]\n",
    "    df_energyrates=df_energyrates.dropna(axis=1)\n",
    "\n",
    "    # filtering demand rates\n",
    "    demandrates = [col for col in cols if 'demandratestructure' in col ]\n",
    "    df_demandrates = df_final[demandrates]\n",
    "    df_demandrates=df_demandrates.dropna(axis=1)\n",
    "\n",
    "    df_fixed_rate = df_final['fixedchargefirstmeter'] \n",
    "\n",
    "    schedules = ['demandweekdayschedule', 'demandweekendschedule', 'energyweekdayschedule', 'energyweekendschedule']\n",
    "    for schedule in  schedules:  \n",
    "\n",
    "        demandSchedule_updated= df_final[schedule].str.split(\",\")\n",
    "        demandSchedule_updated_1 =[ str(row).replace(\"L\",\"\") for row in demandSchedule_updated.values]\n",
    "        demandSchedule_updated_1 =[ str(row).replace(\"]\",\"\") for row in demandSchedule_updated_1]\n",
    "        demandSchedule_updated_1 =[ str(row).replace(\"[\",\"\") for row in demandSchedule_updated_1]\n",
    "        demandSchedule_updated_1 =[ str(row).replace(\"'\",\"\") for row in demandSchedule_updated_1]\n",
    "        demandSchedule_updated_final= demandSchedule_updated_1[0].split(\",\")\n",
    "\n",
    "        df_periods = pd.DataFrame()\n",
    "        for i in range(0, len(demandSchedule_updated_final)):\n",
    "            month = math.floor(i/24) + 1\n",
    "            hrs = i - math.floor(i/24)*24\n",
    "            df_periods.at[month,'hr'+str(hrs)] = int(demandSchedule_updated_final[i])\n",
    "        df_periods.index.names = ['Months']\n",
    "        if schedule == 'demandweekdayschedule':\n",
    "            df_periods_demand_weekday = df_periods\n",
    "        elif schedule == 'demandweekendschedule':\n",
    "            df_periods_demand_weekend = df_periods\n",
    "        elif schedule == 'energyweekdayschedule':\n",
    "            df_periods_energy_weekday = df_periods\n",
    "        elif schedule == 'energyweekendschedule':\n",
    "            df_periods_energy_weekend = df_periods\n",
    "\n",
    "    return [df_periods_demand_weekday, df_periods_demand_weekend, df_periods_energy_weekday, df_periods_energy_weekend,df_energyrates,df_demandrates,df_fixed_rate]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reading FDD results file\n",
    "# df_result = pd.read_csv(configs[\"dir_results\"] + \"/{}_{}.csv\".format( configs[\"weather\"], configs[\"train_test_apply\"] ))\n",
    "\n",
    "# # creating empty dataframe with timestamp\n",
    "# freq = str(configs['impact_est_timestep_min']) + 'min'\n",
    "# df_combined = pd.DataFrame([])\n",
    "# df_combined['reading_time'] = pd.date_range( configs['streamdata_date_start'], configs['streamdata_date_end'], freq=freq)\n",
    "# df_combined = df_combined.set_index(['reading_time'])[:-1]\n",
    "# timestamp_last = df_combined.index[-1]\n",
    "\n",
    "# # expanding FDD results into the same user-specified timestep\n",
    "# df_result_exp = np.repeat(list(df_result.values), configs['fdd_reporting_frequency_hrs']*int(60/configs['impact_est_timestep_min']))\n",
    "# df_result_exp = pd.DataFrame(df_result_exp)\n",
    "# df_result_exp.columns = ['FaultType']\n",
    "# df_result_exp.index = df_combined.index\n",
    "\n",
    "# # setting timestamp for raw simulation data\n",
    "# freq_raw = str(configs['simulation_timestep_min']) + 'min'\n",
    "# df_index = pd.DataFrame([])\n",
    "# df_index['reading_time'] = pd.date_range( configs['simulation_date_start'], configs['simulation_date_end'], freq=freq_raw)\n",
    "# df_index = df_index.set_index(['reading_time'])[:-1]\n",
    "\n",
    "# # reading baseline simulation results\n",
    "# print(\"[Estimating Fault Impact] reading baseline simulation results\")\n",
    "# df_baseline = pd.read_csv(configs['dir_data']+\"/\"+configs['weather']+\"/baseline.csv\", usecols=[configs['sensor_name_elec'], configs['sensor_name_ng']])\n",
    "# df_baseline.columns = [f\"baseline_elec_{configs['sensor_unit_elec']}\",f\"baseline_ng_{configs['sensor_unit_ng']}\"]\n",
    "# df_baseline.index = df_index.index\n",
    "# df_baseline = df_baseline.resample(str(configs['impact_est_timestep_min'])+\"T\").mean()\n",
    "\n",
    "# # recreating FDD results with unique fault type (consecutive fault types are removed)\n",
    "# df_unique = df_result_exp[(df_result_exp.ne(df_result_exp.shift())).any(axis=1)]\n",
    "# df_unique = df_unique.reset_index()\n",
    "\n",
    "# # reading individual fault simulation results (based on FDD results) and creating whole year combined results\n",
    "# count = 1\n",
    "# print(\"[Estimating Fault Impact] combining simulation results from the FDD results\")\n",
    "# df_combined_temp = pd.DataFrame()\n",
    "# for index, row in df_unique.iterrows():\n",
    "\n",
    "#     # specifying start and stop timestamp for each detected fault\n",
    "#     rownum_current = df_unique.loc[df_unique.index==index,:].index[0]\n",
    "#     timestamp_start = df_unique.iloc[rownum_current,:].reading_time\n",
    "#     if rownum_current+1 < df_unique.shape[0]:\n",
    "#         timestamp_end = df_unique.iloc[rownum_current+1,:].reading_time - pd.Timedelta(minutes=configs[\"simulation_timestep_min\"])\n",
    "#     else:\n",
    "#         timestamp_end = timestamp_last\n",
    "\n",
    "#     print(f\"[Estimating Fault Impact] prossessing [{row['FaultType']} ({count}/{df_unique.shape[0]})] from the FDD results covering {timestamp_start} to {timestamp_end}\")\n",
    "\n",
    "#     count_file = 0\n",
    "#     for file in glob.glob(configs['dir_data']+\"/\"+configs['weather']+f\"/*{row['FaultType']}*\"):\n",
    "#         print(f\"[Estimating Fault Impact] reading [{file}] file\")\n",
    "#         count_file += 1\n",
    "#         if count_file == 1:\n",
    "#             df_temp = pd.read_csv(file, usecols=[configs['sensor_name_elec'], configs['sensor_name_ng']])\n",
    "#             df_temp.index = df_index.index\n",
    "#             df_temp = df_temp.resample(str(configs['impact_est_timestep_min'])+\"T\").mean()\n",
    "#             df_temp = df_temp[timestamp_start:timestamp_end]\n",
    "#             df_fault = df_temp.copy()\n",
    "#         else:\n",
    "#             df_temp = pd.read_csv(file, usecols=[configs['sensor_name_elec'], configs['sensor_name_ng']])\n",
    "#             df_temp.index = df_index.index\n",
    "#             df_temp = df_temp.resample(str(configs['impact_est_timestep_min'])+\"T\").mean()\n",
    "#             df_temp = df_temp[timestamp_start:timestamp_end]\n",
    "#             df_fault += df_temp\n",
    "\n",
    "#     # averaging all fault intensity simulations for a single fault and merging into combined dataframe\n",
    "#     print(f\"[Estimating Fault Impact] averaging all fault intensity simulations for a single fault and merging into combined dataframe\")\n",
    "#     df_fault = df_fault/count_file\n",
    "#     df_fault['fdd_result'] = row['FaultType']\n",
    "#     df_combined_temp = pd.concat([df_combined_temp, df_fault])\n",
    "#     count+=1\n",
    "\n",
    "# # creating combined dataframe from baseline and faulted timeseries data\n",
    "# df_combined_temp.columns = [f\"faulted_elec_{configs['sensor_unit_elec']}\",f\"faulted_ng_{configs['sensor_unit_ng']}\", \"fdd_result\"]\n",
    "# df_combined_temp.index = pd.to_datetime(df_combined_temp.index)\n",
    "# df_combined = pd.merge(df_combined, df_baseline, how='outer', left_index=True, right_index=True)\n",
    "# df_combined = pd.merge(df_combined, df_combined_temp, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# # creating columns of energy usage differences\n",
    "# df_combined['diff_elec'] = df_combined[\"faulted_elec_{}\".format(configs[\"sensor_unit_elec\"])] - df_combined[\"baseline_elec_{}\".format(configs[\"sensor_unit_elec\"])]\n",
    "# df_combined['diff_ng'] = df_combined[\"faulted_ng_{}\".format(configs[\"sensor_unit_ng\"])] - df_combined[\"baseline_ng_{}\".format(configs[\"sensor_unit_ng\"])]\n",
    "\n",
    "# # creating columns for time, date, and month\n",
    "# df_combined['Time'] = pd.to_datetime(df_combined.index).time\n",
    "# df_combined['Time'] = df_combined.Time.astype(str).str.rsplit(\":\",1, expand=True).iloc[:,0]\n",
    "# df_combined['Date'] = pd.to_datetime(df_combined.index).date\n",
    "# df_combined['Month'] = pd.to_datetime(df_combined.index).month\n",
    "# df_combined = df_combined.dropna()\n",
    "\n",
    "# # calculate monthly and annual excess energy usages\n",
    "# if (configs['sensor_unit_ng']=='W') & (configs['sensor_unit_elec']=='W'):\n",
    "#     df_monthly = df_combined.groupby(['Month'])[[\"baseline_elec_{}\".format(configs[\"sensor_unit_elec\"]),\"baseline_ng_{}\".format(configs[\"sensor_unit_ng\"]),'diff_elec','diff_ng']].sum()/1000/(60/configs['impact_est_timestep_min']) #convert W to kWh\n",
    "#     base_annual_elec = round(df_monthly[\"baseline_elec_{}\".format(configs[\"sensor_unit_elec\"])].sum()) # in kWh\n",
    "#     base_annual_ng = round(df_monthly[\"baseline_ng_{}\".format(configs[\"sensor_unit_ng\"])].sum()) # in kWh\n",
    "#     diff_annual_elec = round(df_monthly.sum()['diff_elec']) # in kWh\n",
    "#     diff_annual_ng = round(df_monthly.sum()['diff_ng']) # in kWh\n",
    "#     perc_annual_elec = round(diff_annual_elec/base_annual_elec*100, 3) # in %\n",
    "#     perc_annual_ng = round(diff_annual_ng/base_annual_ng*100, 3) # in %\n",
    "# else:\n",
    "#     # add other unit conversions\n",
    "#     print(\"[Estimating Fault Impact] unit conversion from {} for electricity and {} for natural gas to kWh is not currently supported\".format(configs['sensor_unit_elec'],configs['sensor_unit_ng']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined.to_csv(\"./df_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv(\"./df_combined.csv\", index_col=0)\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.index = pd.to_datetime(df_combined.index,format='%Y-%m-%d %H:%M:%S')\n",
    "df_combined.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading utility values from utility database\n",
    "df_rates = pd.read_csv(configs['dir_data'] + '/cost_data/utility_data.csv')\n",
    "[df_periods_demand_weekday, df_periods_demand_weekend, df_periods_energy_weekday, df_periods_energy_weekend,df_energyrates,df_demandrates,df_fixed_rate] = utilRates(df_rates, configs['rate_elec_utility'], configs['rate_elec_sector'], configs['rate_elec_name'])  \n",
    "df_combined['baseline_ng_therms'] = df_combined['baseline_ng_W']* 0.034130/1000\n",
    "df_combined['faulted_ng_therms'] = df_combined['faulted_ng_W']* 0.034130/1000   \n",
    "df_combined = df_combined.reset_index()\n",
    "\n",
    "# electricity cost estimation - demand\n",
    "dict_month = {\n",
    "    1:31,\n",
    "    2:28,\n",
    "    3:31,\n",
    "    4:30,\n",
    "    5:31,\n",
    "    6:30,\n",
    "    7:31,\n",
    "    8:31,\n",
    "    9:30,\n",
    "    10:31,\n",
    "    11:30,\n",
    "    12:31\n",
    "}\n",
    "df_combined_monthly = df_combined.groupby(by=\"Month\").sum()\n",
    "df_combined_monthly['rate_elec_subscription_cost_$'] = [df_fixed_rate[0]]*df_combined_monthly.shape[0]\n",
    "cases = ['baseline_elec_W','faulted_elec_W']\n",
    "for case in cases:\n",
    "    title = case + '_demand_cost_$'\n",
    "    for month in dict_month.keys():\n",
    "        df_month = df_combined.loc[df_combined['Month'] == month]\n",
    "        if df_month.shape[0] == 0:\n",
    "            continue\n",
    "        df_peak =df_month[df_month[case] == df_month[case].max()].reset_index()\n",
    "        df_peak_hour = df_peak['reading_time'][0].hour\n",
    "        if df_combined['reading_time'][i].weekday() <+ 4: #weekday\n",
    "            columns = df_periods_demand_weekday.columns\n",
    "            for col in columns:\n",
    "                if str(df_peak_hour) in col:\n",
    "                    col_needed = col\n",
    "                    break\n",
    "            filtered_col_demand = df_periods_demand_weekday[col_needed]     \n",
    "            rate_needed_demand = filtered_col_demand.loc[month]\n",
    "        else: # weekend\n",
    "            columns = df_periods_demand_weekend.columns\n",
    "            for col in columns:\n",
    "                if str(df_peak_hour) in col:\n",
    "                    col_needed = col\n",
    "                    break\n",
    "            filtered_col_demand = df_periods_demand_weekend[col_needed]     \n",
    "            rate_needed_demand = filtered_col_demand.loc[month]   \n",
    "        rate_cost = 0\n",
    "        for col in df_demandrates.columns: \n",
    "            if 'period'+str(int(rate_needed_demand)) in col:\n",
    "                rate_cost = rate_cost + df_demandrates[col][0]\n",
    "        demand_cost = rate_cost * df_month[case].max()/1000\n",
    "        df_combined_monthly.at[month,title] = demand_cost \n",
    "df_combined_monthly = df_combined_monthly.rename(columns={'baseline_elec_W_demand_cost_$':'baseline_elec_demand_cost_$', 'faulted_elec_W_demand_cost_$':'faulted_elec_demand_cost_$'})\n",
    "df_combined_monthly = df_combined_monthly.reset_index()\n",
    "df_combined['baseline_elec_demand_cost_$'] = 0\n",
    "df_combined['faulted_elec_demand_cost_$'] = 0\n",
    "for mnth in df_combined.Month.unique():\n",
    "    df_combined.loc[df_combined.Month == mnth, 'baseline_elec_demand_cost_$'] = df_combined_monthly.loc[df_combined_monthly.Month==mnth, 'baseline_elec_demand_cost_$'].iloc[0] / dict_month[mnth]\n",
    "    df_combined.loc[df_combined.Month == mnth, 'faulted_elec_demand_cost_$'] = df_combined_monthly.loc[df_combined_monthly.Month==mnth, 'faulted_elec_demand_cost_$'].iloc[0] / dict_month[mnth]\n",
    "\n",
    "# electricity cost estimation - energy \n",
    "for i in range(0,len(df_combined)):\n",
    "    month = df_combined['reading_time'][i].month\n",
    "    hr = df_combined['reading_time'][i].hour\n",
    "    if df_combined['reading_time'][i].weekday() <= 4: #weekday\n",
    "        columns = df_periods_energy_weekday.columns\n",
    "        for col in columns:\n",
    "            if str(hr) in col:\n",
    "                col_needed = col\n",
    "                break\n",
    "        filtered_col_kwh = df_periods_energy_weekday[col_needed]\n",
    "        rate_needed_kwh = filtered_col_kwh.loc[month]        \n",
    "        df_combined.at[i,'rate_kwh'] = rate_needed_kwh\n",
    "    else: # weekend\n",
    "        columns = df_periods_energy_weekend.columns\n",
    "        for col in columns:\n",
    "            if str(hr) in col:\n",
    "                col_needed = col\n",
    "                break\n",
    "        filtered_col_kwh = df_periods_energy_weekend[col_needed]\n",
    "        rate_needed_kwh = filtered_col_kwh.loc[month]\n",
    "        df_combined.at[i,'rate_kwh'] = rate_needed_kwh\n",
    "    rate_cost = 0\n",
    "    for col in df_energyrates.columns: \n",
    "        if 'period'+str(int(rate_needed_kwh)) in col:\n",
    "            rate_cost = rate_cost + df_energyrates[col][0]\n",
    "    df_combined.at[i,'baseline_elec_energy_cost_$'] = rate_cost * df_combined['baseline_elec_W'][i]/1000\n",
    "    df_combined.at[i,'faulted_elec_energy_cost_$'] = rate_cost * df_combined['faulted_elec_W'][i]/1000    \n",
    "\n",
    "# gas cost estimation \n",
    "df_gas_rate = gas_rate(configs['rate_ng_siteid'], configs['rate_ng_year_start'], configs['rate_ng_year_end'])\n",
    "df_gas_rate['Month'] = df_gas_rate.period.str.split(\"M\", expand=True).iloc[:,1].astype(float)\n",
    "df_combined = pd.merge(df_combined, df_gas_rate[['Month','value']], on='Month')\n",
    "df_combined['value'] = df_combined['value'].astype(float)\n",
    "df_combined = df_combined.rename(columns={'value':'rate_ng_$_per_therm'})\n",
    "df_combined['baseline_ng_cost_$'] = df_combined.baseline_ng_therms * df_combined['rate_ng_$_per_therm']\n",
    "df_combined['faulted_ng_cost_$'] = df_combined.faulted_ng_therms * df_combined['rate_ng_$_per_therm']\n",
    "\n",
    "# total cost estimation\n",
    "df_combined['diff_cost_$'] = ( df_combined['faulted_elec_demand_cost_$'] + df_combined['faulted_elec_energy_cost_$'] + df_combined['faulted_ng_cost_$'] ) - ( df_combined['baseline_elec_demand_cost_$'] + df_combined['baseline_elec_energy_cost_$'] + df_combined['baseline_ng_cost_$'] )\n",
    "\n",
    "# impact summary\n",
    "df_impact = pd.DataFrame()\n",
    "df_impact['fault_duration_ratio'] = df_combined.groupby(['fdd_result']).Date.count() / df_combined.shape[0]\n",
    "df_impact['impact_site_energy_elec_kWh'] = df_combined.groupby(['fdd_result']).diff_elec.sum()/1000 # in kWh\n",
    "df_impact['impact_site_energy_ng_kWh'] = df_combined.groupby(['fdd_result']).diff_ng.sum()/1000 # in kWh\n",
    "df_impact['impact_cost_$'] = df_combined.groupby(['fdd_result'])[['diff_cost_$']].sum() # in $\n",
    "df_impact = df_impact.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined.to_csv(\"./df_combined_impact.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined = pd.read_csv(\"./df_combined_impact.csv\", index_col=1)\n",
    "# df_combined.index = pd.to_datetime(df_combined.index,format='%Y-%m-%d %H:%M:%S')\n",
    "# df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------#\n",
    "# plot setting\n",
    "#------------------------------------------------------------#\n",
    "title_font_size = 12\n",
    "colorbar_font_size = 12\n",
    "tick_font_size = 12\n",
    "anot_font_size = 16\n",
    "fontfamily = 'Times New Roman'\n",
    "barwidth = 0.75\n",
    "colorscale = ['rgb(215,25,28)','rgb(253,174,97)','rgb(171,221,164)','rgb(43,131,186)']\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=1, \n",
    "    cols=4, \n",
    "    shared_yaxes=True, \n",
    "    horizontal_spacing=0.05,\n",
    ")  \n",
    "\n",
    "list_plot = [\n",
    "    'fault_duration_ratio',\n",
    "    'impact_site_energy_elec_kWh',\n",
    "    'impact_site_energy_ng_kWh',\n",
    "    'impact_cost_$'\n",
    "]\n",
    "\n",
    "list_title_x = [\n",
    "    \"<b>Diagnosis<br>ratio [-]</b>\",\n",
    "    \"<b>Excess<br>electricity [kWh]</b>\",\n",
    "    \"<b>Excess<br>natural gas [kWh]</b>\",\n",
    "    \"<b>Excess<br>cost [$]</b>\"\n",
    "]\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "# bar plots\n",
    "#------------------------------------------------------------#\n",
    "col=0\n",
    "\n",
    "for plot in list_plot:\n",
    "    \n",
    "    fig.add_trace(go.Bar(\n",
    "        x=df_impact[plot],\n",
    "        y=df_impact.fdd_result,\n",
    "        text=round(df_impact[plot],2),\n",
    "        textposition='auto',\n",
    "        textfont_family=fontfamily,\n",
    "        orientation='h',\n",
    "        marker=dict(\n",
    "            color=colorscale[col],\n",
    "            line=dict(color='black', width=1)\n",
    "        ),\n",
    "        showlegend=False,\n",
    "        width=barwidth,\n",
    "    ),row=1,col=col+1)\n",
    "    \n",
    "    col+=1\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "# axes\n",
    "#------------------------------------------------------------#\n",
    "col=1\n",
    "\n",
    "for title in list_title_x:\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title = dict( \n",
    "            text=title,\n",
    "            font=dict(\n",
    "                family=fontfamily,\n",
    "                size=title_font_size,\n",
    "            ),\n",
    "        ),\n",
    "        tickfont = dict(\n",
    "            family=fontfamily,\n",
    "            size=tick_font_size,\n",
    "        ),\n",
    "        zeroline=True,\n",
    "        zerolinewidth=1,\n",
    "        zerolinecolor='black',\n",
    "        row=1, col=col\n",
    "    )\n",
    "    \n",
    "    col+=1\n",
    "    \n",
    "fig.update_yaxes(\n",
    "    tickfont = dict(\n",
    "        family=fontfamily,\n",
    "        size=tick_font_size,\n",
    "    ),\n",
    ")\n",
    "\n",
    "#------------------------------------------------------------#\n",
    "# axes\n",
    "#------------------------------------------------------------#\n",
    "fig.update_layout(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    margin=dict(\n",
    "        l=200,\n",
    "        r=0,\n",
    "        t=0,\n",
    "        b=50,\n",
    "    ),\n",
    "    plot_bgcolor='white',\n",
    ")\n",
    "\n",
    "# export\n",
    "path_impact_visual = configs['dir_results'] + \"/{}_FDD_impact_figure.svg\".format(configs[\"weather\"])\n",
    "print(\"[Estimating Fault Impact] saving fault impact estimation figure in {}\".format(path_impact_visual))\n",
    "pio.write_image(fig, path_impact_visual)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
